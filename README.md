# ğŸ“˜ Trabalho PrÃ¡tico (Projeto com ClassificaÃ§Ã£o BinÃ¡ria usando LLMs)

---
**Membros da Equipe:**

- Ademir GuimarÃ£es
- Arthur Bezerra
- Debora Barros
- Keven Gomes
- Pedro Carvalho
- Ronald Boadana
---


Este notebook realiza uma **anÃ¡lise exploratÃ³ria de dados** utilizando bibliotecas como **Pandas**, **Matplotlib** e **Seaborn**.  
TambÃ©m sÃ£o aplicadas tÃ©cnicas de **prÃ©-processamento de texto**, como a **remoÃ§Ã£o de pontuaÃ§Ã£o e stopwords** com a biblioteca **NLTK**.

AlÃ©m disso, o projeto faz uso de modelos de linguagem baseados em **Transformers**, com o `SentenceTransformer` para gerar **embeddings semÃ¢nticos** dos textos.  

Para inferÃªncia com **LLMs**, foi utilizado o modelo **LLaMA 3.1â€“8B-Instant**, acessado por meio da **API do Groq**.

---

## âš™ï¸ PrÃ©-requisitos

- Conta no [Kaggle](https://www.kaggle.com) e chave da API (`kaggle.json`)
- Chave de API da [Groq](https://console.groq.com/)

---

## ğŸš€ Como usar

### 1. ğŸ§ª Gere o arquivo .env contendo o nome do modelo e chave de API:
```json
GROQ_API_KEY=api_key
GROQ_MODEL=llama-3.1-8b-instant
```
### 2. ğŸ’¾ Insira o arquivo .env na raiz do projeto.
### 3. ğŸ“¥ Ao rodar tudo, na seÃ§Ã£o **'Explorando o dataset'** insira o arquivo kaggle.json gerado pela API do Kaggle 
```json
{
   "username":"kaggle_username",
   "key":"kaggle_api_key"
}
```
---

## ğŸ§  ObservaÃ§Ãµes
âš ï¸ Os testes foram realizados utilizando o serviÃ§o sob demanda da Groq.
A versÃ£o gratuita do modelo LLaMA 3.1 possui limitaÃ§Ã£o no nÃºmero de tokens por minuto (TPM), o que pode impedir a execuÃ§Ã£o completa dos testes diretamente nessa modalidade.

âš ï¸ Ao rodar no ambiente do Colab, as bibliotecas necessÃ¡rias jÃ¡ estÃ£o no notebook para instalaÃ§Ã£o.


